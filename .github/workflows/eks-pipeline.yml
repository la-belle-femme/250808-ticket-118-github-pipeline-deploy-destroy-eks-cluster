name: EKS Cluster Management

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Select action'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy

env:
  CLUSTER_NAME: github-action-eks-cluster
  AWS_REGION: us-east-1

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-${{ github.run_id }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.7
          terraform_wrapper: false

      - name: Terraform Init
        run: terraform init -input=false

      - name: Terraform Validate
        run: terraform validate

      - name: Terraform Plan
        if: github.event.inputs.action == 'plan'
        run: terraform plan -input=false

      - name: Terraform Apply
        if: github.event.inputs.action == 'apply'
        run: terraform apply -auto-approve -input=false

      - name: Terraform Destroy
        if: github.event.inputs.action == 'destroy'
        timeout-minutes: 60
        run: |
          set -e
          set -o pipefail

          # Verify AWS credentials
          aws sts get-caller-identity

          # Check if cluster exists
          if ! aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} &>/dev/null; then
            echo "::warning::Cluster ${{ env.CLUSTER_NAME }} not found"
            exit 0
          fi

          echo "=== Starting destruction sequence ==="

          # 1. Scale down node groups to zero
          echo "::group::Scaling down node groups"
          nodegroups=$(aws eks list-nodegroups --cluster-name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} --query "nodegroups" --output text || echo "")
          for ng in $nodegroups; do
            aws eks update-nodegroup-config \
              --cluster-name ${{ env.CUSTER_NAME }} \
              --nodegroup-name $ng \
              --region ${{ env.AWS_REGION }} \
              --scaling-config minSize=0,maxSize=0,desiredSize=0 || true
          done
          echo "::endgroup::"

          # 2. Delete node groups
          echo "::group::Deleting node groups"
          for ng in $nodegroups; do
            aws eks delete-nodegroup \
              --cluster-name ${{ env.CLUSTER_NAME }} \
              --nodegroup-name $ng \
              --region ${{ env.AWS_REGION }} || true
          done
          
          # Wait for node group deletion
          for ng in $nodegroups; do
            timeout 900 aws eks wait nodegroup-deleted \
              --cluster-name ${{ env.CLUSTER_NAME }} \
              --nodegroup-name $ng \
              --region ${{ env.AWS_REGION }} || true
          done
          echo "::endgroup::"

          # 3. Run Terraform destroy
          echo "::group::Executing terraform destroy"
          terraform destroy -auto-approve -input=false -refresh=false
          echo "::endgroup::"

          # 4. Final verification
          echo "::group::Verifying destruction"
          if aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} &>/dev/null; then
            echo "::error::Cluster still exists after destroy!"
            exit 1
          else
            echo "Cluster successfully destroyed"
          fi
          echo "::endgroup::"
